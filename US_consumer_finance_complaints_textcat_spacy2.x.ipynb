{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to implement spacy2.x models for text classifcation on the US_consumer_finance_complaints dataset. The data can be downloaded from https://www.kaggle.com/cfpb/us-consumer-finance-complaints. Only the product and consumer_complaint_narrative features are used as categories and text respectively to train a model to classify text into one of the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "df = pd.read_csv('consumer_complaints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_received</th>\n",
       "      <th>product</th>\n",
       "      <th>sub_product</th>\n",
       "      <th>issue</th>\n",
       "      <th>sub_issue</th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "      <th>company_public_response</th>\n",
       "      <th>company</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>tags</th>\n",
       "      <th>consumer_consent_provided</th>\n",
       "      <th>submitted_via</th>\n",
       "      <th>date_sent_to_company</th>\n",
       "      <th>company_response_to_consumer</th>\n",
       "      <th>timely_response</th>\n",
       "      <th>consumer_disputed?</th>\n",
       "      <th>complaint_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/30/2013</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan modification,collection,foreclosure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U.S. Bancorp</td>\n",
       "      <td>CA</td>\n",
       "      <td>95993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Referral</td>\n",
       "      <td>09/03/2013</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>511074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/30/2013</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan servicing, payments, escrow account</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>CA</td>\n",
       "      <td>91104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Referral</td>\n",
       "      <td>09/03/2013</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>511080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/30/2013</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Incorrect information on credit report</td>\n",
       "      <td>Account status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>NY</td>\n",
       "      <td>11764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Postal mail</td>\n",
       "      <td>09/18/2013</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>510473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/30/2013</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Non-federal student loan</td>\n",
       "      <td>Repaying your loan</td>\n",
       "      <td>Repaying your loan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Navient Solutions, Inc.</td>\n",
       "      <td>MD</td>\n",
       "      <td>21402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Email</td>\n",
       "      <td>08/30/2013</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>510326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/30/2013</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>False statements or representation</td>\n",
       "      <td>Attempted to collect wrong amount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Resurgent Capital Services L.P.</td>\n",
       "      <td>GA</td>\n",
       "      <td>30106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>08/30/2013</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>511067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_received           product               sub_product  \\\n",
       "0    08/30/2013          Mortgage            Other mortgage   \n",
       "1    08/30/2013          Mortgage            Other mortgage   \n",
       "2    08/30/2013  Credit reporting                       NaN   \n",
       "3    08/30/2013      Student loan  Non-federal student loan   \n",
       "4    08/30/2013   Debt collection               Credit card   \n",
       "\n",
       "                                      issue  \\\n",
       "0  Loan modification,collection,foreclosure   \n",
       "1  Loan servicing, payments, escrow account   \n",
       "2    Incorrect information on credit report   \n",
       "3                        Repaying your loan   \n",
       "4        False statements or representation   \n",
       "\n",
       "                           sub_issue consumer_complaint_narrative  \\\n",
       "0                                NaN                          NaN   \n",
       "1                                NaN                          NaN   \n",
       "2                     Account status                          NaN   \n",
       "3                 Repaying your loan                          NaN   \n",
       "4  Attempted to collect wrong amount                          NaN   \n",
       "\n",
       "  company_public_response                          company state zipcode tags  \\\n",
       "0                     NaN                     U.S. Bancorp    CA   95993  NaN   \n",
       "1                     NaN            Wells Fargo & Company    CA   91104  NaN   \n",
       "2                     NaN            Wells Fargo & Company    NY   11764  NaN   \n",
       "3                     NaN          Navient Solutions, Inc.    MD   21402  NaN   \n",
       "4                     NaN  Resurgent Capital Services L.P.    GA   30106  NaN   \n",
       "\n",
       "  consumer_consent_provided submitted_via date_sent_to_company  \\\n",
       "0                       NaN      Referral           09/03/2013   \n",
       "1                       NaN      Referral           09/03/2013   \n",
       "2                       NaN   Postal mail           09/18/2013   \n",
       "3                       NaN         Email           08/30/2013   \n",
       "4                       NaN           Web           08/30/2013   \n",
       "\n",
       "  company_response_to_consumer timely_response consumer_disputed?  \\\n",
       "0      Closed with explanation             Yes                Yes   \n",
       "1      Closed with explanation             Yes                Yes   \n",
       "2      Closed with explanation             Yes                 No   \n",
       "3      Closed with explanation             Yes                Yes   \n",
       "4      Closed with explanation             Yes                Yes   \n",
       "\n",
       "   complaint_id  \n",
       "0        511074  \n",
       "1        511080  \n",
       "2        510473  \n",
       "3        510326  \n",
       "4        511067  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 555957 entries, 0 to 555956\n",
      "Data columns (total 18 columns):\n",
      " #   Column                        Non-Null Count   Dtype \n",
      "---  ------                        --------------   ----- \n",
      " 0   date_received                 555957 non-null  object\n",
      " 1   product                       555957 non-null  object\n",
      " 2   sub_product                   397635 non-null  object\n",
      " 3   issue                         555957 non-null  object\n",
      " 4   sub_issue                     212622 non-null  object\n",
      " 5   consumer_complaint_narrative  66806 non-null   object\n",
      " 6   company_public_response       85124 non-null   object\n",
      " 7   company                       555957 non-null  object\n",
      " 8   state                         551070 non-null  object\n",
      " 9   zipcode                       551452 non-null  object\n",
      " 10  tags                          77959 non-null   object\n",
      " 11  consumer_consent_provided     123458 non-null  object\n",
      " 12  submitted_via                 555957 non-null  object\n",
      " 13  date_sent_to_company          555957 non-null  object\n",
      " 14  company_response_to_consumer  555957 non-null  object\n",
      " 15  timely_response               555957 non-null  object\n",
      " 16  consumer_disputed?            555957 non-null  object\n",
      " 17  complaint_id                  555957 non-null  int64 \n",
      "dtypes: int64(1), object(17)\n",
      "memory usage: 76.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "consumer_complaint_narrative    489151\n",
       "tags                            477998\n",
       "company_public_response         470833\n",
       "consumer_consent_provided       432499\n",
       "sub_issue                       343335\n",
       "sub_product                     158322\n",
       "state                             4887\n",
       "zipcode                           4505\n",
       "product                              0\n",
       "issue                                0\n",
       "complaint_id                         0\n",
       "company                              0\n",
       "consumer_disputed?                   0\n",
       "submitted_via                        0\n",
       "date_sent_to_company                 0\n",
       "company_response_to_consumer         0\n",
       "timely_response                      0\n",
       "date_received                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out the number of null valuesby column\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all the rows with null values in the 'consumer_complaint_narrative' column as that is the column we will \n",
    "# be using for our analysis\n",
    "df.dropna(subset=['consumer_complaint_narrative'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tags                            55389\n",
       "company_public_response         34030\n",
       "sub_issue                       33874\n",
       "sub_product                     20455\n",
       "zipcode                           189\n",
       "state                             186\n",
       "company                             0\n",
       "product                             0\n",
       "issue                               0\n",
       "consumer_complaint_narrative        0\n",
       "complaint_id                        0\n",
       "consumer_disputed?                  0\n",
       "consumer_consent_provided           0\n",
       "submitted_via                       0\n",
       "date_sent_to_company                0\n",
       "company_response_to_consumer        0\n",
       "timely_response                     0\n",
       "date_received                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to make sure all the null values in the required column have been dropped\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 66806 entries, 190126 to 553096\n",
      "Data columns (total 18 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   date_received                 66806 non-null  object\n",
      " 1   product                       66806 non-null  object\n",
      " 2   sub_product                   46351 non-null  object\n",
      " 3   issue                         66806 non-null  object\n",
      " 4   sub_issue                     32932 non-null  object\n",
      " 5   consumer_complaint_narrative  66806 non-null  object\n",
      " 6   company_public_response       32776 non-null  object\n",
      " 7   company                       66806 non-null  object\n",
      " 8   state                         66620 non-null  object\n",
      " 9   zipcode                       66617 non-null  object\n",
      " 10  tags                          11417 non-null  object\n",
      " 11  consumer_consent_provided     66806 non-null  object\n",
      " 12  submitted_via                 66806 non-null  object\n",
      " 13  date_sent_to_company          66806 non-null  object\n",
      " 14  company_response_to_consumer  66806 non-null  object\n",
      " 15  timely_response               66806 non-null  object\n",
      " 16  consumer_disputed?            66806 non-null  object\n",
      " 17  complaint_id                  66806 non-null  int64 \n",
      "dtypes: int64(1), object(17)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe with the only two columns required for our analysis\n",
    "df = df[['product', 'consumer_complaint_narrative']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean text\n",
    "def clean_text_round1(text):\n",
    "    text = text.lower()                                                 # lowercase text\n",
    "    text = re.sub('\\{.*?\\}', '', text)                                  # remove text in curly brackets\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)     # remove punctuations\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)                                 # remove numbers like dates\n",
    "    text = re.sub('\\n', '', text)                                       # remove new line characters\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['consumer_complaint_narrative'].apply(clean_text_round1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190126</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>XXXX has claimed I owe them {$27.00} for XXXX ...</td>\n",
       "      <td>xxxx has claimed i owe them  for xxxx years de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190135</th>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>Due to inconsistencies in the amount owed that...</td>\n",
       "      <td>due to inconsistencies in the amount owed that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190155</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>In XX/XX/XXXX my wages that I earned at my job...</td>\n",
       "      <td>in xxxxxxxx my wages that i earned at my job d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190207</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>I have an open and current mortgage with Chase...</td>\n",
       "      <td>i have an open and current mortgage with chase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190208</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>XXXX was submitted XX/XX/XXXX. At the time I s...</td>\n",
       "      <td>xxxx was submitted xxxxxxxx at the time i subm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                product                       consumer_complaint_narrative  \\\n",
       "190126  Debt collection  XXXX has claimed I owe them {$27.00} for XXXX ...   \n",
       "190135    Consumer Loan  Due to inconsistencies in the amount owed that...   \n",
       "190155         Mortgage  In XX/XX/XXXX my wages that I earned at my job...   \n",
       "190207         Mortgage  I have an open and current mortgage with Chase...   \n",
       "190208         Mortgage  XXXX was submitted XX/XX/XXXX. At the time I s...   \n",
       "\n",
       "                                               clean_text  \n",
       "190126  xxxx has claimed i owe them  for xxxx years de...  \n",
       "190135  due to inconsistencies in the amount owed that...  \n",
       "190155  in xxxxxxxx my wages that i earned at my job d...  \n",
       "190207  i have an open and current mortgage with chase...  \n",
       "190208  xxxx was submitted xxxxxxxx at the time i subm...  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, world'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to remove xx's\n",
    "def remove_xx(text):\n",
    "    words = str(text).split()\n",
    "    for word in words:\n",
    "        if len(word) >= 2:\n",
    "            if word[0] == 'x' and word[1] == 'x':\n",
    "                words.remove(word)\n",
    "            \n",
    "    return ' '.join(words)\n",
    "\n",
    "remove_xx('hello, world xxxxxxxxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['clean_text'].map(lambda x: remove_xx(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "df['clean_text'] = df['clean_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190126</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>XXXX has claimed I owe them {$27.00} for XXXX ...</td>\n",
       "      <td>claimed owe years despite proof payment sent c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190135</th>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>Due to inconsistencies in the amount owed that...</td>\n",
       "      <td>due inconsistencies amount owed told bank amou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190155</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>In XX/XX/XXXX my wages that I earned at my job...</td>\n",
       "      <td>wages earned job decreased almost half knew tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190207</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>I have an open and current mortgage with Chase...</td>\n",
       "      <td>open current mortgage chase bank chase reporti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190208</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>XXXX was submitted XX/XX/XXXX. At the time I s...</td>\n",
       "      <td>submitted time submitted complaint dealt rushm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                product                       consumer_complaint_narrative  \\\n",
       "190126  Debt collection  XXXX has claimed I owe them {$27.00} for XXXX ...   \n",
       "190135    Consumer Loan  Due to inconsistencies in the amount owed that...   \n",
       "190155         Mortgage  In XX/XX/XXXX my wages that I earned at my job...   \n",
       "190207         Mortgage  I have an open and current mortgage with Chase...   \n",
       "190208         Mortgage  XXXX was submitted XX/XX/XXXX. At the time I s...   \n",
       "\n",
       "                                               clean_text  \n",
       "190126  claimed owe years despite proof payment sent c...  \n",
       "190135  due inconsistencies amount owed told bank amou...  \n",
       "190155  wages earned job decreased almost half knew tr...  \n",
       "190207  open current mortgage chase bank chase reporti...  \n",
       "190208  submitted time submitted complaint dealt rushm...  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is enough preprocessing for now\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    " # only the first 1000 rows to save time during training\n",
    "df = df[['product', 'clean_text']][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190126</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>claimed owe years despite proof payment sent c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190135</th>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>due inconsistencies amount owed told bank amou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190155</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>wages earned job decreased almost half knew tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190207</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>open current mortgage chase bank chase reporti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190208</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>submitted time submitted complaint dealt rushm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                product                                         clean_text\n",
       "190126  Debt collection  claimed owe years despite proof payment sent c...\n",
       "190135    Consumer Loan  due inconsistencies amount owed told bank amou...\n",
       "190155         Mortgage  wages earned job decreased almost half knew tr...\n",
       "190207         Mortgage  open current mortgage chase bank chase reporti...\n",
       "190208         Mortgage  submitted time submitted complaint dealt rushm..."
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 190126 to 203247\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   product     1000 non-null   object\n",
      " 1   clean_text  1000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 23.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>product</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190126</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>claimed owe years despite proof payment sent c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190135</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>due inconsistencies amount owed told bank amou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190155</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>wages earned job decreased almost half knew tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190207</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>open current mortgage chase bank chase reporti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190208</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>submitted time submitted complaint dealt rushm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>203235</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>credit report reporting appears account online...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>203241</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>credit card accounts capital one earlier year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>203244</td>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>bank america bank took whole check account go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>203246</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>received tax abatement escrow payment balance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>203247</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>mortgage behind appx sent green tree servicer ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                  product  \\\n",
       "0    190126          Debt collection   \n",
       "1    190135            Consumer Loan   \n",
       "2    190155                 Mortgage   \n",
       "3    190207                 Mortgage   \n",
       "4    190208                 Mortgage   \n",
       "..      ...                      ...   \n",
       "995  203235            Consumer Loan   \n",
       "996  203241              Credit card   \n",
       "997  203244  Bank account or service   \n",
       "998  203246                 Mortgage   \n",
       "999  203247                 Mortgage   \n",
       "\n",
       "                                            clean_text  \n",
       "0    claimed owe years despite proof payment sent c...  \n",
       "1    due inconsistencies amount owed told bank amou...  \n",
       "2    wages earned job decreased almost half knew tr...  \n",
       "3    open current mortgage chase bank chase reporti...  \n",
       "4    submitted time submitted complaint dealt rushm...  \n",
       "..                                                 ...  \n",
       "995  credit report reporting appears account online...  \n",
       "996  credit card accounts capital one earlier year ...  \n",
       "997  bank america bank took whole check account go ...  \n",
       "998  received tax abatement escrow payment balance ...  \n",
       "999  mortgage behind appx sent green tree servicer ...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset index\n",
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Debt collection            28.3\n",
       "Mortgage                   23.3\n",
       "Credit reporting           14.3\n",
       "Credit card                12.0\n",
       "Bank account or service     7.8\n",
       "Consumer Loan               5.7\n",
       "Student loan                4.7\n",
       "Money transfers             1.7\n",
       "Payday loan                 1.3\n",
       "Prepaid card                0.7\n",
       "Other financial service     0.2\n",
       "Name: product, dtype: float64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the frequency of each category\n",
    "100.0*df['product'].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "The idea here is to use the text in the 'consumer_complaint_narrative' column to categorise it to the right category "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train/test/valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Debt collection',\n",
       " 'Consumer Loan',\n",
       " 'Mortgage',\n",
       " 'Credit card',\n",
       " 'Credit reporting',\n",
       " 'Student loan',\n",
       " 'Bank account or service',\n",
       " 'Payday loan',\n",
       " 'Money transfers',\n",
       " 'Other financial service',\n",
       " 'Prepaid card']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_values = list(df['product'].unique())\n",
    "label_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(df['clean_text'],\n",
    "                                                   df['product'],\n",
    "                                                   test_size=0.2,\n",
    "                                                   stratify=df['product']\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X: (800,)\n",
      "Shape of train_y: (800,)\n",
      "Shape of test_X: (200,)\n",
      "Shape of test_y: (200,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of train_X:', train_X.shape)\n",
    "print('Shape of train_y:', train_y.shape)\n",
    "print('Shape of test_X:', test_X.shape)\n",
    "print('Shape of test_y:', test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset to spacy compatible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode all the labels\n",
    "train_y_df = pd.get_dummies(train_y)\n",
    "test_y_df = pd.get_dummies(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bank account or service</th>\n",
       "      <th>Consumer Loan</th>\n",
       "      <th>Credit card</th>\n",
       "      <th>Credit reporting</th>\n",
       "      <th>Debt collection</th>\n",
       "      <th>Money transfers</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Other financial service</th>\n",
       "      <th>Payday loan</th>\n",
       "      <th>Prepaid card</th>\n",
       "      <th>Student loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199871</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200030</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199616</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200500</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200691</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bank account or service  Consumer Loan  Credit card  Credit reporting  \\\n",
       "199871                        0              0            0                 0   \n",
       "200030                        1              0            0                 0   \n",
       "199616                        0              0            0                 0   \n",
       "200500                        0              0            0                 1   \n",
       "200691                        0              0            0                 0   \n",
       "\n",
       "        Debt collection  Money transfers  Mortgage  Other financial service  \\\n",
       "199871                1                0         0                        0   \n",
       "200030                0                0         0                        0   \n",
       "199616                0                0         1                        0   \n",
       "200500                0                0         0                        0   \n",
       "200691                0                0         1                        0   \n",
       "\n",
       "        Payday loan  Prepaid card  Student loan  \n",
       "199871            0             0             0  \n",
       "200030            0             0             0  \n",
       "199616            0             0             0  \n",
       "200500            0             0             0  \n",
       "200691            0             0             0  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to text list and label dictionaries\n",
    "train_texts = train_X.tolist()\n",
    "train_cats = train_y_df.to_dict(orient='records')\n",
    "test_texts = test_X.tolist()\n",
    "test_cats = test_y_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the text and labels to create data in spacy format\n",
    "train_data = list(zip(train_texts, [{'cats': cats} for cats in train_cats]))\n",
    "test_data = list(zip(test_texts, [{'cats': cats} for cats in test_cats]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ended service receiving final statement notice additional charges needed corrected contacted informed errors ticket created amend bill new updated bill sent business days bill never received called regards bill customer service observed bill still waiting supervisor approval corrections another ticket created marked urgent corrections new bill received credit alert stating account turned third party collections agency spoke representative rom southwest credit stated attempting collect past due bill explain charges incorrect bill reviewed corrections requested transferred billing time stated third party collections hired contacted spoke reviewed bill supervisor corrected also sent request remove account third party collections contacted check status account still collections customer service representative stated first request denied collection agency refused remove request created second ticket requested account removed collections collection agency updated payment amount contacted xxxxxxxx referenced second request account removed form collections informed collections agency denied requested payment contacted southwest credit inquired request form stated never received request took information stated would call back continued call dates request final statement request third party collection agency removed account repeatedly told provide final bill requested pay amount informed told several calls would get updated bill mail customer service representative xxxxxxxx told function allow send update statement changes charges requested speak manager supervisor informed bill sent collections error stated would remove paid requested updated statement refused send one requested another ticket generated remove collections denied stating tickets hade sent already manager xxxx stated needed pay today account stay collections continued recognize error billing stated bill paid would remove form collections informed would submit payment ability view updated statement third party collections removed account stated would send bill trust balance accurate reported collections remain pay',\n",
       "  {'cats': {'Bank account or service': 0,\n",
       "    'Consumer Loan': 0,\n",
       "    'Credit card': 0,\n",
       "    'Credit reporting': 0,\n",
       "    'Debt collection': 1,\n",
       "    'Money transfers': 0,\n",
       "    'Mortgage': 0,\n",
       "    'Other financial service': 0,\n",
       "    'Payday loan': 0,\n",
       "    'Prepaid card': 0,\n",
       "    'Student loan': 0}}),\n",
       " ('former bank kept bank account open putting taking money account keep charging fees',\n",
       "  {'cats': {'Bank account or service': 1,\n",
       "    'Consumer Loan': 0,\n",
       "    'Credit card': 0,\n",
       "    'Credit reporting': 0,\n",
       "    'Debt collection': 0,\n",
       "    'Money transfers': 0,\n",
       "    'Mortgage': 0,\n",
       "    'Other financial service': 0,\n",
       "    'Payday loan': 0,\n",
       "    'Prepaid card': 0,\n",
       "    'Student loan': 0}})]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "train_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('subscribed cancelled within first days service also shipped back equipment within days well saying owe fee refuse pay owe',\n",
       "  {'cats': {'Bank account or service': 0,\n",
       "    'Consumer Loan': 0,\n",
       "    'Credit card': 0,\n",
       "    'Credit reporting': 0,\n",
       "    'Debt collection': 1,\n",
       "    'Money transfers': 0,\n",
       "    'Mortgage': 0,\n",
       "    'Payday loan': 0,\n",
       "    'Prepaid card': 0,\n",
       "    'Student loan': 0}}),\n",
       " ('mortgage company made payment arrangements days later said would nt take payments',\n",
       "  {'cats': {'Bank account or service': 0,\n",
       "    'Consumer Loan': 0,\n",
       "    'Credit card': 0,\n",
       "    'Credit reporting': 0,\n",
       "    'Debt collection': 0,\n",
       "    'Money transfers': 0,\n",
       "    'Mortgage': 1,\n",
       "    'Payday loan': 0,\n",
       "    'Prepaid card': 0,\n",
       "    'Student loan': 0}})]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "test_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack the text and lables used for evaluation later\n",
    "train_texts, train_labels = list(zip(*train_data))\n",
    "test_texts, test_labels = list(zip(*test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spacy(iterations, model_arch, dropout, learn_rate):\n",
    "\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "    textcat = nlp.create_pipe('textcat', config={'exclusive_classes':True, 'architecture':model_arch})\n",
    "    nlp.add_pipe(textcat)\n",
    "\n",
    "    for _, label in enumerate(label_values):\n",
    "        textcat.add_label(label)\n",
    "\n",
    "    pipe_exceptions = ['textcat']\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "    with nlp.disable_pipes(*other_pipes):\n",
    "    #     print(nlp.pipe_names)\n",
    "        optimizer = nlp.begin_training()\n",
    "        optimizer.learn_rate = learn_rate\n",
    "        print('Training the model..')\n",
    "        total_start_time = time.clock()\n",
    "\n",
    "    for i in range(iterations):\n",
    "        print('\\nIteration:', str(i+1))\n",
    "        start_time = time.clock()\n",
    "        losses = {}\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "\n",
    "        random.shuffle(train_data)\n",
    "        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=dropout, losses=losses)\n",
    "\n",
    "        with textcat.model.use_params(optimizer.averages):\n",
    "\n",
    "            docs = [nlp.tokenizer(text) for text in test_texts]\n",
    "\n",
    "            for j, doc in enumerate(textcat.pipe(docs)):\n",
    "                true_series = pd.Series(test_labels[j]['cats'])\n",
    "                true_label = true_series.idxmax()\n",
    "                true_labels.append(true_label)\n",
    "\n",
    "                pred_series = pd.Series(doc.cats)\n",
    "                pred_label = pred_series.idxmax()\n",
    "                pred_labels.append(pred_label)\n",
    "\n",
    "            score_f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
    "            score_ac = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "            print('textcat_loss: {:.3f}\\t f1_score: {:.3f}\\t accuracy_score: {:.3f}'.format(losses['textcat'], score_f1, score_ac))\n",
    "\n",
    "            print('Elapsed time:', str(round((time.clock() - start_time)/60,2)) + ' minutes')\n",
    "            \n",
    "    print('Total time:', str(round((time.clock() - total_start_time)/60,2)) + ' minutes')\n",
    "            \n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model..\n",
      "\n",
      "Iteration: 1\n",
      "textcat_loss: 9.368\t f1_score: 0.562\t accuracy_score: 0.630\n",
      "Elapsed time: 0.67 minutes\n",
      "\n",
      "Iteration: 2\n",
      "textcat_loss: 6.224\t f1_score: 0.626\t accuracy_score: 0.680\n",
      "Elapsed time: 0.58 minutes\n",
      "\n",
      "Iteration: 3\n",
      "textcat_loss: 4.375\t f1_score: 0.634\t accuracy_score: 0.685\n",
      "Elapsed time: 0.57 minutes\n",
      "\n",
      "Iteration: 4\n",
      "textcat_loss: 3.226\t f1_score: 0.660\t accuracy_score: 0.705\n",
      "Elapsed time: 0.57 minutes\n",
      "\n",
      "Iteration: 5\n",
      "textcat_loss: 2.501\t f1_score: 0.675\t accuracy_score: 0.715\n",
      "Elapsed time: 0.59 minutes\n",
      "\n",
      "Iteration: 6\n",
      "textcat_loss: 2.062\t f1_score: 0.681\t accuracy_score: 0.720\n",
      "Elapsed time: 0.61 minutes\n",
      "\n",
      "Iteration: 7\n",
      "textcat_loss: 1.687\t f1_score: 0.684\t accuracy_score: 0.720\n",
      "Elapsed time: 0.75 minutes\n",
      "\n",
      "Iteration: 8\n",
      "textcat_loss: 1.335\t f1_score: 0.689\t accuracy_score: 0.725\n",
      "Elapsed time: 0.97 minutes\n",
      "\n",
      "Iteration: 9\n",
      "textcat_loss: 1.116\t f1_score: 0.694\t accuracy_score: 0.730\n",
      "Elapsed time: 1.04 minutes\n",
      "\n",
      "Iteration: 10\n",
      "textcat_loss: 0.945\t f1_score: 0.686\t accuracy_score: 0.720\n",
      "Elapsed time: 2.01 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7feef1981160>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bag of words model architecture\n",
    "train_spacy(10, 'bow', 0.2, 4e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model..\n",
      "\n",
      "Iteration: 1\n",
      "textcat_loss: 6.909\t f1_score: 0.765\t accuracy_score: 0.780\n",
      "Elapsed time: 0.7 minutes\n",
      "\n",
      "Iteration: 2\n",
      "textcat_loss: 1.860\t f1_score: 0.712\t accuracy_score: 0.730\n",
      "Elapsed time: 0.71 minutes\n",
      "\n",
      "Iteration: 3\n",
      "textcat_loss: 0.737\t f1_score: 0.703\t accuracy_score: 0.730\n",
      "Elapsed time: 1.46 minutes\n",
      "\n",
      "Iteration: 4\n",
      "textcat_loss: 0.380\t f1_score: 0.706\t accuracy_score: 0.735\n",
      "Elapsed time: 0.98 minutes\n",
      "\n",
      "Iteration: 5\n",
      "textcat_loss: 0.353\t f1_score: 0.744\t accuracy_score: 0.760\n",
      "Elapsed time: 2.46 minutes\n",
      "\n",
      "Iteration: 6\n",
      "textcat_loss: 0.204\t f1_score: 0.732\t accuracy_score: 0.750\n",
      "Elapsed time: 3.06 minutes\n",
      "\n",
      "Iteration: 7\n",
      "textcat_loss: 0.102\t f1_score: 0.729\t accuracy_score: 0.745\n",
      "Elapsed time: 2.92 minutes\n",
      "\n",
      "Iteration: 8\n",
      "textcat_loss: 0.061\t f1_score: 0.708\t accuracy_score: 0.735\n",
      "Elapsed time: 3.63 minutes\n",
      "\n",
      "Iteration: 9\n",
      "textcat_loss: 0.121\t f1_score: 0.698\t accuracy_score: 0.725\n",
      "Elapsed time: 3.5 minutes\n",
      "\n",
      "Iteration: 10\n",
      "textcat_loss: 0.150\t f1_score: 0.711\t accuracy_score: 0.735\n",
      "Elapsed time: 3.06 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fef16df6fd0>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a different learning rate for bow\n",
    "train_spacy(10, 'bow', 0.2, 4e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model..\n",
      "\n",
      "Iteration: 1\n",
      "textcat_loss: 9.043\t f1_score: 0.535\t accuracy_score: 0.605\n",
      "Elapsed time: 0.72 minutes\n",
      "\n",
      "Iteration: 2\n",
      "textcat_loss: 6.229\t f1_score: 0.593\t accuracy_score: 0.650\n",
      "Elapsed time: 0.73 minutes\n",
      "\n",
      "Iteration: 3\n",
      "textcat_loss: 4.255\t f1_score: 0.712\t accuracy_score: 0.735\n",
      "Elapsed time: 1.03 minutes\n",
      "\n",
      "Iteration: 4\n",
      "textcat_loss: 3.029\t f1_score: 0.717\t accuracy_score: 0.730\n",
      "Elapsed time: 1.37 minutes\n",
      "\n",
      "Iteration: 5\n",
      "textcat_loss: 1.831\t f1_score: 0.737\t accuracy_score: 0.745\n",
      "Elapsed time: 2.83 minutes\n",
      "\n",
      "Iteration: 6\n",
      "textcat_loss: 1.613\t f1_score: 0.723\t accuracy_score: 0.735\n",
      "Elapsed time: 3.13 minutes\n",
      "\n",
      "Iteration: 7\n",
      "textcat_loss: 1.163\t f1_score: 0.722\t accuracy_score: 0.725\n",
      "Elapsed time: 2.91 minutes\n",
      "\n",
      "Iteration: 8\n",
      "textcat_loss: 0.736\t f1_score: 0.720\t accuracy_score: 0.730\n",
      "Elapsed time: 3.81 minutes\n",
      "\n",
      "Iteration: 9\n",
      "textcat_loss: 0.599\t f1_score: 0.717\t accuracy_score: 0.725\n",
      "Elapsed time: 3.39 minutes\n",
      "\n",
      "Iteration: 10\n",
      "textcat_loss: 0.588\t f1_score: 0.705\t accuracy_score: 0.715\n",
      "Elapsed time: 2.83 minutes\n",
      "Total time: 22.75 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fef3880a710>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convolutional neural network as model architecture\n",
    "train_spacy(10, 'simple_cnn', 0.2, 4e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model..\n",
      "\n",
      "Iteration: 1\n",
      "textcat_loss: 9.235\t f1_score: 0.508\t accuracy_score: 0.570\n",
      "Elapsed time: 1.05 minutes\n",
      "\n",
      "Iteration: 2\n",
      "textcat_loss: 6.580\t f1_score: 0.638\t accuracy_score: 0.665\n",
      "Elapsed time: 1.2 minutes\n",
      "\n",
      "Iteration: 3\n",
      "textcat_loss: 5.604\t f1_score: 0.723\t accuracy_score: 0.730\n",
      "Elapsed time: 1.64 minutes\n",
      "\n",
      "Iteration: 4\n",
      "textcat_loss: 4.349\t f1_score: 0.681\t accuracy_score: 0.680\n",
      "Elapsed time: 1.71 minutes\n",
      "\n",
      "Iteration: 5\n",
      "textcat_loss: 3.843\t f1_score: 0.716\t accuracy_score: 0.720\n",
      "Elapsed time: 2.92 minutes\n",
      "\n",
      "Iteration: 6\n",
      "textcat_loss: 2.944\t f1_score: 0.718\t accuracy_score: 0.720\n",
      "Elapsed time: 3.55 minutes\n",
      "\n",
      "Iteration: 7\n",
      "textcat_loss: 2.823\t f1_score: 0.737\t accuracy_score: 0.740\n",
      "Elapsed time: 3.57 minutes\n",
      "\n",
      "Iteration: 8\n",
      "textcat_loss: 2.100\t f1_score: 0.742\t accuracy_score: 0.745\n",
      "Elapsed time: 4.12 minutes\n",
      "\n",
      "Iteration: 9\n",
      "textcat_loss: 2.163\t f1_score: 0.744\t accuracy_score: 0.745\n",
      "Elapsed time: 3.78 minutes\n",
      "\n",
      "Iteration: 10\n",
      "textcat_loss: 1.669\t f1_score: 0.728\t accuracy_score: 0.725\n",
      "Elapsed time: 3.26 minutes\n",
      "Total time: 26.82 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fed734d6d68>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble model architecture\n",
    "train_spacy(10, 'ensemble', 0.2, 4e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trf_train_spacy(iterations, dropout, learn_rate):\n",
    "\n",
    "    nlp = spacy.load('en_trf_bertbaseuncased_lg')\n",
    "\n",
    "    textcat = nlp.create_pipe('trf_textcat', config={'exclusive_classes':True})\n",
    "\n",
    "    for _, label in enumerate(label_values):\n",
    "        textcat.add_label(label)\n",
    "        \n",
    "    nlp.add_pipe(textcat)\n",
    "\n",
    "#     pipe_exceptions = ['textcat']\n",
    "#     other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    \n",
    "    optimizer = nlp.resume_training()\n",
    "    optimizer.learn_rate = learn_rate\n",
    "    print('Training the model..')\n",
    "\n",
    "    for i in range(iterations):\n",
    "        print('\\nIteration:', str(i+1))\n",
    "        start_time = time.clock()\n",
    "        losses = {}\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "        b = 0\n",
    "        random.shuffle(train_data)\n",
    "        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=dropout, losses=losses)\n",
    "            b += 1\n",
    "            print('Batch:', b)\n",
    "            total_start_time = time.clock()\n",
    "            \n",
    "#         print(i, losses)\n",
    "\n",
    "        with textcat.model.use_params(optimizer.averages):\n",
    "\n",
    "            docs = [nlp(text) for text in test_texts]\n",
    "\n",
    "            for j, doc in enumerate(textcat.pipe(docs)):\n",
    "                true_series = pd.Series(test_labels[j]['cats'])\n",
    "                true_label = true_series.idxmax()\n",
    "                true_labels.append(true_label)\n",
    "\n",
    "                pred_series = pd.Series(doc.cats)\n",
    "                pred_label = pred_series.idxmax()\n",
    "                pred_labels.append(pred_label)\n",
    "\n",
    "            score_f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
    "            score_ac = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "            print('textcat_loss: {:.3f}\\t f1_score: {:.3f}\\t accuracy_score: {:.3f}'.format(losses['trf_textcat'], score_f1, score_ac))\n",
    "\n",
    "            print('Elapsed time:', str(round((time.clock() - start_time)/60,2)) + ' minutes')\n",
    "    \n",
    "    print('Total time:', str(round((time.clock() - total_start_time)/60,2)) + ' minutes')\n",
    "    \n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model..\n",
      "\n",
      "Iteration: 1\n",
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n",
      "Batch: 10\n",
      "Batch: 11\n",
      "Batch: 12\n",
      "Batch: 13\n",
      "Batch: 14\n",
      "Batch: 15\n",
      "Batch: 16\n",
      "Batch: 17\n",
      "Batch: 18\n",
      "Batch: 19\n",
      "Batch: 20\n",
      "Batch: 21\n",
      "Batch: 22\n",
      "Batch: 23\n",
      "Batch: 24\n",
      "Batch: 25\n",
      "Batch: 26\n",
      "Batch: 27\n",
      "Batch: 28\n",
      "Batch: 29\n",
      "Batch: 30\n",
      "Batch: 31\n",
      "Batch: 32\n",
      "Batch: 33\n",
      "Batch: 34\n",
      "Batch: 35\n",
      "Batch: 36\n",
      "Batch: 37\n",
      "Batch: 38\n",
      "Batch: 39\n",
      "Batch: 40\n",
      "Batch: 41\n",
      "Batch: 42\n",
      "Batch: 43\n",
      "Batch: 44\n",
      "Batch: 45\n",
      "Batch: 46\n",
      "Batch: 47\n",
      "Batch: 48\n",
      "Batch: 49\n",
      "Batch: 50\n",
      "Batch: 51\n",
      "Batch: 52\n",
      "Batch: 53\n",
      "Batch: 54\n",
      "Batch: 55\n",
      "Batch: 56\n",
      "Batch: 57\n",
      "Batch: 58\n",
      "Batch: 59\n",
      "Batch: 60\n",
      "Batch: 61\n",
      "Batch: 62\n",
      "Batch: 63\n",
      "Batch: 64\n",
      "Batch: 65\n",
      "Batch: 66\n",
      "Batch: 67\n",
      "Batch: 68\n",
      "Batch: 69\n",
      "Batch: 70\n",
      "Batch: 71\n",
      "Batch: 72\n",
      "Batch: 73\n",
      "Batch: 74\n",
      "Batch: 75\n",
      "Batch: 76\n",
      "Batch: 77\n",
      "Batch: 78\n",
      "Batch: 79\n",
      "Batch: 80\n",
      "Batch: 81\n",
      "Batch: 82\n",
      "Batch: 83\n",
      "Batch: 84\n",
      "Batch: 85\n",
      "Batch: 86\n",
      "Batch: 87\n",
      "Batch: 88\n",
      "Batch: 89\n",
      "Batch: 90\n",
      "Batch: 91\n",
      "Batch: 92\n",
      "Batch: 93\n",
      "Batch: 94\n",
      "Batch: 95\n",
      "Batch: 96\n",
      "Batch: 97\n",
      "Batch: 98\n",
      "Batch: 99\n",
      "Batch: 100\n",
      "Batch: 101\n",
      "Batch: 102\n",
      "Batch: 103\n",
      "Batch: 104\n",
      "Batch: 105\n",
      "Batch: 106\n",
      "Batch: 107\n",
      "Batch: 108\n",
      "Batch: 109\n",
      "Batch: 110\n",
      "Batch: 111\n",
      "Batch: 112\n",
      "Batch: 113\n",
      "Batch: 114\n",
      "Batch: 115\n",
      "Batch: 116\n",
      "Batch: 117\n",
      "Batch: 118\n",
      "Batch: 119\n",
      "Batch: 120\n",
      "Batch: 121\n",
      "Batch: 122\n",
      "Batch: 123\n",
      "Batch: 124\n",
      "Batch: 125\n",
      "Batch: 126\n",
      "Batch: 127\n",
      "Batch: 128\n",
      "Batch: 129\n",
      "Batch: 130\n",
      "Batch: 131\n",
      "Batch: 132\n",
      "Batch: 133\n",
      "Batch: 134\n",
      "Batch: 135\n",
      "Batch: 136\n",
      "Batch: 137\n",
      "Batch: 138\n",
      "Batch: 139\n",
      "Batch: 140\n",
      "Batch: 141\n",
      "Batch: 142\n",
      "Batch: 143\n",
      "Batch: 144\n",
      "Batch: 145\n",
      "Batch: 146\n",
      "Batch: 147\n",
      "Batch: 148\n",
      "Batch: 149\n",
      "Batch: 150\n",
      "Batch: 151\n",
      "Batch: 152\n",
      "Batch: 153\n",
      "Batch: 154\n",
      "Batch: 155\n",
      "Batch: 156\n",
      "Batch: 157\n",
      "Batch: 158\n",
      "Batch: 159\n",
      "Batch: 160\n",
      "Batch: 161\n",
      "Batch: 162\n",
      "Batch: 163\n",
      "Batch: 164\n",
      "Batch: 165\n",
      "Batch: 166\n",
      "Batch: 167\n",
      "Batch: 168\n",
      "Batch: 169\n",
      "Batch: 170\n",
      "Batch: 171\n",
      "Batch: 172\n",
      "Batch: 173\n",
      "Batch: 174\n",
      "Batch: 175\n",
      "Batch: 176\n",
      "Batch: 177\n",
      "Batch: 178\n",
      "Batch: 179\n",
      "Batch: 180\n",
      "Batch: 181\n",
      "Batch: 182\n",
      "Batch: 183\n",
      "Batch: 184\n",
      "Batch: 185\n",
      "Batch: 186\n",
      "Batch: 187\n",
      "Batch: 188\n",
      "Batch: 189\n",
      "Batch: 190\n",
      "Batch: 191\n",
      "Batch: 192\n",
      "Batch: 193\n",
      "Batch: 194\n",
      "Batch: 195\n",
      "Batch: 196\n",
      "Batch: 197\n",
      "Batch: 198\n",
      "Batch: 199\n",
      "Batch: 200\n",
      "textcat_loss: 11.220\t f1_score: 0.126\t accuracy_score: 0.285\n",
      "Elapsed time: 50.43 minutes\n",
      "\n",
      "Iteration: 2\n",
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n",
      "Batch: 10\n",
      "Batch: 11\n",
      "Batch: 12\n",
      "Batch: 13\n",
      "Batch: 14\n",
      "Batch: 15\n",
      "Batch: 16\n",
      "Batch: 17\n",
      "Batch: 18\n",
      "Batch: 19\n",
      "Batch: 20\n",
      "Batch: 21\n",
      "Batch: 22\n",
      "Batch: 23\n",
      "Batch: 24\n",
      "Batch: 25\n",
      "Batch: 26\n",
      "Batch: 27\n",
      "Batch: 28\n",
      "Batch: 29\n",
      "Batch: 30\n",
      "Batch: 31\n",
      "Batch: 32\n",
      "Batch: 33\n",
      "Batch: 34\n",
      "Batch: 35\n",
      "Batch: 36\n",
      "Batch: 37\n",
      "Batch: 38\n",
      "Batch: 39\n",
      "Batch: 40\n",
      "Batch: 41\n",
      "Batch: 42\n",
      "Batch: 43\n",
      "Batch: 44\n",
      "Batch: 45\n",
      "Batch: 46\n",
      "Batch: 47\n",
      "Batch: 48\n",
      "Batch: 49\n",
      "Batch: 50\n",
      "Batch: 51\n",
      "Batch: 52\n",
      "Batch: 53\n",
      "Batch: 54\n",
      "Batch: 55\n",
      "Batch: 56\n",
      "Batch: 57\n",
      "Batch: 58\n",
      "Batch: 59\n",
      "Batch: 60\n",
      "Batch: 61\n",
      "Batch: 62\n",
      "Batch: 63\n",
      "Batch: 64\n",
      "Batch: 65\n",
      "Batch: 66\n",
      "Batch: 67\n",
      "Batch: 68\n",
      "Batch: 69\n",
      "Batch: 70\n",
      "Batch: 71\n",
      "Batch: 72\n",
      "Batch: 73\n",
      "Batch: 74\n",
      "Batch: 75\n",
      "Batch: 76\n",
      "Batch: 77\n",
      "Batch: 78\n",
      "Batch: 79\n",
      "Batch: 80\n",
      "Batch: 81\n",
      "Batch: 82\n",
      "Batch: 83\n",
      "Batch: 84\n",
      "Batch: 85\n",
      "Batch: 86\n",
      "Batch: 87\n",
      "Batch: 88\n",
      "Batch: 89\n",
      "Batch: 90\n",
      "Batch: 91\n",
      "Batch: 92\n",
      "Batch: 93\n",
      "Batch: 94\n",
      "Batch: 95\n",
      "Batch: 96\n",
      "Batch: 97\n",
      "Batch: 98\n",
      "Batch: 99\n",
      "Batch: 100\n",
      "Batch: 101\n",
      "Batch: 102\n",
      "Batch: 103\n",
      "Batch: 104\n",
      "Batch: 105\n",
      "Batch: 106\n",
      "Batch: 107\n",
      "Batch: 108\n",
      "Batch: 109\n",
      "Batch: 110\n",
      "Batch: 111\n",
      "Batch: 112\n",
      "Batch: 113\n",
      "Batch: 114\n",
      "Batch: 115\n",
      "Batch: 116\n",
      "Batch: 117\n",
      "Batch: 118\n",
      "Batch: 119\n",
      "Batch: 120\n",
      "Batch: 121\n",
      "Batch: 122\n",
      "Batch: 123\n",
      "Batch: 124\n",
      "Batch: 125\n",
      "Batch: 126\n",
      "Batch: 127\n",
      "Batch: 128\n",
      "Batch: 129\n",
      "Batch: 130\n",
      "Batch: 131\n",
      "Batch: 132\n",
      "Batch: 133\n",
      "Batch: 134\n",
      "Batch: 135\n",
      "Batch: 136\n",
      "Batch: 137\n",
      "Batch: 138\n",
      "Batch: 139\n",
      "Batch: 140\n",
      "Batch: 141\n",
      "Batch: 142\n",
      "Batch: 143\n",
      "Batch: 144\n",
      "Batch: 145\n",
      "Batch: 146\n",
      "Batch: 147\n",
      "Batch: 148\n",
      "Batch: 149\n",
      "Batch: 150\n",
      "Batch: 151\n",
      "Batch: 152\n",
      "Batch: 153\n",
      "Batch: 154\n",
      "Batch: 155\n",
      "Batch: 156\n",
      "Batch: 157\n",
      "Batch: 158\n",
      "Batch: 159\n",
      "Batch: 160\n",
      "Batch: 161\n",
      "Batch: 162\n",
      "Batch: 163\n",
      "Batch: 164\n",
      "Batch: 165\n",
      "Batch: 166\n",
      "Batch: 167\n",
      "Batch: 168\n",
      "Batch: 169\n",
      "Batch: 170\n",
      "Batch: 171\n",
      "Batch: 172\n",
      "Batch: 173\n",
      "Batch: 174\n",
      "Batch: 175\n",
      "Batch: 176\n",
      "Batch: 177\n",
      "Batch: 178\n",
      "Batch: 179\n",
      "Batch: 180\n",
      "Batch: 181\n",
      "Batch: 182\n",
      "Batch: 183\n",
      "Batch: 184\n",
      "Batch: 185\n",
      "Batch: 186\n",
      "Batch: 187\n",
      "Batch: 188\n",
      "Batch: 189\n",
      "Batch: 190\n",
      "Batch: 191\n",
      "Batch: 192\n",
      "Batch: 193\n",
      "Batch: 194\n",
      "Batch: 195\n",
      "Batch: 196\n",
      "Batch: 197\n",
      "Batch: 198\n",
      "Batch: 199\n",
      "Batch: 200\n",
      "textcat_loss: 10.590\t f1_score: 0.126\t accuracy_score: 0.285\n",
      "Elapsed time: 57.32 minutes\n",
      "\n",
      "Iteration: 3\n",
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n",
      "Batch: 10\n",
      "Batch: 11\n",
      "Batch: 12\n",
      "Batch: 13\n",
      "Batch: 14\n",
      "Batch: 15\n",
      "Batch: 16\n",
      "Batch: 17\n",
      "Batch: 18\n",
      "Batch: 19\n",
      "Batch: 20\n",
      "Batch: 21\n",
      "Batch: 22\n",
      "Batch: 23\n",
      "Batch: 24\n",
      "Batch: 25\n",
      "Batch: 26\n",
      "Batch: 27\n",
      "Batch: 28\n",
      "Batch: 29\n",
      "Batch: 30\n",
      "Batch: 31\n",
      "Batch: 32\n",
      "Batch: 33\n",
      "Batch: 34\n",
      "Batch: 35\n",
      "Batch: 36\n",
      "Batch: 37\n",
      "Batch: 38\n",
      "Batch: 39\n",
      "Batch: 40\n",
      "Batch: 41\n",
      "Batch: 42\n",
      "Batch: 43\n",
      "Batch: 44\n",
      "Batch: 45\n",
      "Batch: 46\n",
      "Batch: 47\n",
      "Batch: 48\n",
      "Batch: 49\n",
      "Batch: 50\n",
      "Batch: 51\n",
      "Batch: 52\n",
      "Batch: 53\n",
      "Batch: 54\n",
      "Batch: 55\n",
      "Batch: 56\n",
      "Batch: 57\n",
      "Batch: 58\n",
      "Batch: 59\n",
      "Batch: 60\n",
      "Batch: 61\n",
      "Batch: 62\n",
      "Batch: 63\n",
      "Batch: 64\n",
      "Batch: 65\n",
      "Batch: 66\n",
      "Batch: 67\n",
      "Batch: 68\n",
      "Batch: 69\n",
      "Batch: 70\n",
      "Batch: 71\n",
      "Batch: 72\n",
      "Batch: 73\n",
      "Batch: 74\n",
      "Batch: 75\n",
      "Batch: 76\n",
      "Batch: 77\n",
      "Batch: 78\n",
      "Batch: 79\n",
      "Batch: 80\n",
      "Batch: 81\n",
      "Batch: 82\n",
      "Batch: 83\n",
      "Batch: 84\n",
      "Batch: 85\n",
      "Batch: 86\n",
      "Batch: 87\n",
      "Batch: 88\n",
      "Batch: 89\n",
      "Batch: 90\n",
      "Batch: 91\n",
      "Batch: 92\n",
      "Batch: 93\n",
      "Batch: 94\n",
      "Batch: 95\n",
      "Batch: 96\n",
      "Batch: 97\n",
      "Batch: 98\n",
      "Batch: 99\n",
      "Batch: 100\n",
      "Batch: 101\n",
      "Batch: 102\n",
      "Batch: 103\n",
      "Batch: 104\n",
      "Batch: 105\n",
      "Batch: 106\n",
      "Batch: 107\n",
      "Batch: 108\n",
      "Batch: 109\n",
      "Batch: 110\n",
      "Batch: 111\n",
      "Batch: 112\n",
      "Batch: 113\n",
      "Batch: 114\n",
      "Batch: 115\n",
      "Batch: 116\n",
      "Batch: 117\n",
      "Batch: 118\n",
      "Batch: 119\n",
      "Batch: 120\n",
      "Batch: 121\n",
      "Batch: 122\n",
      "Batch: 123\n",
      "Batch: 124\n",
      "Batch: 125\n",
      "Batch: 126\n",
      "Batch: 127\n",
      "Batch: 128\n",
      "Batch: 129\n",
      "Batch: 130\n",
      "Batch: 131\n",
      "Batch: 132\n",
      "Batch: 133\n",
      "Batch: 134\n",
      "Batch: 135\n",
      "Batch: 136\n",
      "Batch: 137\n",
      "Batch: 138\n",
      "Batch: 139\n",
      "Batch: 140\n",
      "Batch: 141\n",
      "Batch: 142\n",
      "Batch: 143\n",
      "Batch: 144\n",
      "Batch: 145\n",
      "Batch: 146\n",
      "Batch: 147\n",
      "Batch: 148\n",
      "Batch: 149\n",
      "Batch: 150\n",
      "Batch: 151\n",
      "Batch: 152\n",
      "Batch: 153\n",
      "Batch: 154\n",
      "Batch: 155\n",
      "Batch: 156\n",
      "Batch: 157\n",
      "Batch: 158\n",
      "Batch: 159\n",
      "Batch: 160\n",
      "Batch: 161\n",
      "Batch: 162\n",
      "Batch: 163\n",
      "Batch: 164\n",
      "Batch: 165\n",
      "Batch: 166\n",
      "Batch: 167\n",
      "Batch: 168\n",
      "Batch: 169\n",
      "Batch: 170\n",
      "Batch: 171\n",
      "Batch: 172\n",
      "Batch: 173\n",
      "Batch: 174\n",
      "Batch: 175\n",
      "Batch: 176\n",
      "Batch: 177\n",
      "Batch: 178\n",
      "Batch: 179\n",
      "Batch: 180\n",
      "Batch: 181\n",
      "Batch: 182\n",
      "Batch: 183\n",
      "Batch: 184\n",
      "Batch: 185\n",
      "Batch: 186\n",
      "Batch: 187\n",
      "Batch: 188\n",
      "Batch: 189\n",
      "Batch: 190\n",
      "Batch: 191\n",
      "Batch: 192\n",
      "Batch: 193\n",
      "Batch: 194\n",
      "Batch: 195\n",
      "Batch: 196\n",
      "Batch: 197\n",
      "Batch: 198\n",
      "Batch: 199\n",
      "Batch: 200\n",
      "textcat_loss: 10.583\t f1_score: 0.126\t accuracy_score: 0.285\n",
      "Elapsed time: 62.3 minutes\n",
      "\n",
      "Iteration: 4\n",
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n",
      "Batch: 10\n",
      "Batch: 11\n",
      "Batch: 12\n",
      "Batch: 13\n",
      "Batch: 14\n",
      "Batch: 15\n",
      "Batch: 16\n",
      "Batch: 17\n",
      "Batch: 18\n",
      "Batch: 19\n",
      "Batch: 20\n",
      "Batch: 21\n",
      "Batch: 22\n",
      "Batch: 23\n",
      "Batch: 24\n",
      "Batch: 25\n",
      "Batch: 26\n",
      "Batch: 27\n",
      "Batch: 28\n",
      "Batch: 29\n",
      "Batch: 30\n",
      "Batch: 31\n",
      "Batch: 32\n",
      "Batch: 33\n",
      "Batch: 34\n",
      "Batch: 35\n",
      "Batch: 36\n",
      "Batch: 37\n",
      "Batch: 38\n",
      "Batch: 39\n",
      "Batch: 40\n",
      "Batch: 41\n",
      "Batch: 42\n",
      "Batch: 43\n",
      "Batch: 44\n",
      "Batch: 45\n",
      "Batch: 46\n",
      "Batch: 47\n",
      "Batch: 48\n",
      "Batch: 49\n",
      "Batch: 50\n",
      "Batch: 51\n",
      "Batch: 52\n",
      "Batch: 53\n",
      "Batch: 54\n",
      "Batch: 55\n",
      "Batch: 56\n",
      "Batch: 57\n",
      "Batch: 58\n",
      "Batch: 59\n",
      "Batch: 60\n",
      "Batch: 61\n",
      "Batch: 62\n",
      "Batch: 63\n",
      "Batch: 64\n",
      "Batch: 65\n",
      "Batch: 66\n",
      "Batch: 67\n",
      "Batch: 68\n",
      "Batch: 69\n",
      "Batch: 70\n",
      "Batch: 71\n",
      "Batch: 72\n",
      "Batch: 73\n",
      "Batch: 74\n",
      "Batch: 75\n",
      "Batch: 76\n",
      "Batch: 77\n",
      "Batch: 78\n",
      "Batch: 79\n",
      "Batch: 80\n",
      "Batch: 81\n",
      "Batch: 82\n",
      "Batch: 83\n",
      "Batch: 84\n",
      "Batch: 85\n",
      "Batch: 86\n",
      "Batch: 87\n",
      "Batch: 88\n",
      "Batch: 89\n",
      "Batch: 90\n",
      "Batch: 91\n",
      "Batch: 92\n",
      "Batch: 93\n",
      "Batch: 94\n",
      "Batch: 95\n",
      "Batch: 96\n",
      "Batch: 97\n",
      "Batch: 98\n",
      "Batch: 99\n",
      "Batch: 100\n",
      "Batch: 101\n",
      "Batch: 102\n",
      "Batch: 103\n",
      "Batch: 104\n",
      "Batch: 105\n",
      "Batch: 106\n",
      "Batch: 107\n",
      "Batch: 108\n",
      "Batch: 109\n",
      "Batch: 110\n",
      "Batch: 111\n",
      "Batch: 112\n",
      "Batch: 113\n",
      "Batch: 114\n",
      "Batch: 115\n",
      "Batch: 116\n",
      "Batch: 117\n",
      "Batch: 118\n",
      "Batch: 119\n",
      "Batch: 120\n",
      "Batch: 121\n",
      "Batch: 122\n",
      "Batch: 123\n",
      "Batch: 124\n",
      "Batch: 125\n",
      "Batch: 126\n",
      "Batch: 127\n",
      "Batch: 128\n",
      "Batch: 129\n",
      "Batch: 130\n",
      "Batch: 131\n",
      "Batch: 132\n",
      "Batch: 133\n",
      "Batch: 134\n",
      "Batch: 135\n",
      "Batch: 136\n",
      "Batch: 137\n",
      "Batch: 138\n",
      "Batch: 139\n",
      "Batch: 140\n",
      "Batch: 141\n",
      "Batch: 142\n",
      "Batch: 143\n",
      "Batch: 144\n",
      "Batch: 145\n",
      "Batch: 146\n",
      "Batch: 147\n",
      "Batch: 148\n",
      "Batch: 149\n",
      "Batch: 150\n",
      "Batch: 151\n",
      "Batch: 152\n",
      "Batch: 153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 154\n",
      "Batch: 155\n",
      "Batch: 156\n",
      "Batch: 157\n",
      "Batch: 158\n",
      "Batch: 159\n",
      "Batch: 160\n",
      "Batch: 161\n",
      "Batch: 162\n",
      "Batch: 163\n",
      "Batch: 164\n",
      "Batch: 165\n",
      "Batch: 166\n",
      "Batch: 167\n",
      "Batch: 168\n",
      "Batch: 169\n",
      "Batch: 170\n",
      "Batch: 171\n",
      "Batch: 172\n",
      "Batch: 173\n",
      "Batch: 174\n",
      "Batch: 175\n",
      "Batch: 176\n",
      "Batch: 177\n",
      "Batch: 178\n",
      "Batch: 179\n",
      "Batch: 180\n",
      "Batch: 181\n",
      "Batch: 182\n",
      "Batch: 183\n",
      "Batch: 184\n",
      "Batch: 185\n",
      "Batch: 186\n",
      "Batch: 187\n",
      "Batch: 188\n",
      "Batch: 189\n",
      "Batch: 190\n",
      "Batch: 191\n",
      "Batch: 192\n",
      "Batch: 193\n",
      "Batch: 194\n",
      "Batch: 195\n",
      "Batch: 196\n",
      "Batch: 197\n",
      "Batch: 198\n",
      "Batch: 199\n",
      "Batch: 200\n",
      "textcat_loss: 10.610\t f1_score: 0.126\t accuracy_score: 0.285\n",
      "Elapsed time: 61.66 minutes\n",
      "\n",
      "Iteration: 5\n",
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n",
      "Batch: 10\n",
      "Batch: 11\n",
      "Batch: 12\n",
      "Batch: 13\n",
      "Batch: 14\n",
      "Batch: 15\n",
      "Batch: 16\n",
      "Batch: 17\n",
      "Batch: 18\n",
      "Batch: 19\n",
      "Batch: 20\n",
      "Batch: 21\n",
      "Batch: 22\n",
      "Batch: 23\n",
      "Batch: 24\n",
      "Batch: 25\n",
      "Batch: 26\n",
      "Batch: 27\n",
      "Batch: 28\n",
      "Batch: 29\n",
      "Batch: 30\n",
      "Batch: 31\n",
      "Batch: 32\n",
      "Batch: 33\n",
      "Batch: 34\n",
      "Batch: 35\n",
      "Batch: 36\n",
      "Batch: 37\n",
      "Batch: 38\n",
      "Batch: 39\n",
      "Batch: 40\n",
      "Batch: 41\n",
      "Batch: 42\n",
      "Batch: 43\n",
      "Batch: 44\n",
      "Batch: 45\n",
      "Batch: 46\n",
      "Batch: 47\n",
      "Batch: 48\n",
      "Batch: 49\n",
      "Batch: 50\n",
      "Batch: 51\n",
      "Batch: 52\n",
      "Batch: 53\n",
      "Batch: 54\n",
      "Batch: 55\n",
      "Batch: 56\n",
      "Batch: 57\n",
      "Batch: 58\n",
      "Batch: 59\n",
      "Batch: 60\n",
      "Batch: 61\n",
      "Batch: 62\n",
      "Batch: 63\n",
      "Batch: 64\n",
      "Batch: 65\n",
      "Batch: 66\n",
      "Batch: 67\n",
      "Batch: 68\n",
      "Batch: 69\n",
      "Batch: 70\n",
      "Batch: 71\n",
      "Batch: 72\n",
      "Batch: 73\n",
      "Batch: 74\n",
      "Batch: 75\n",
      "Batch: 76\n",
      "Batch: 77\n",
      "Batch: 78\n",
      "Batch: 79\n",
      "Batch: 80\n",
      "Batch: 81\n",
      "Batch: 82\n",
      "Batch: 83\n",
      "Batch: 84\n",
      "Batch: 85\n",
      "Batch: 86\n",
      "Batch: 87\n",
      "Batch: 88\n",
      "Batch: 89\n",
      "Batch: 90\n",
      "Batch: 91\n",
      "Batch: 92\n",
      "Batch: 93\n",
      "Batch: 94\n",
      "Batch: 95\n",
      "Batch: 96\n",
      "Batch: 97\n",
      "Batch: 98\n",
      "Batch: 99\n",
      "Batch: 100\n",
      "Batch: 101\n",
      "Batch: 102\n",
      "Batch: 103\n",
      "Batch: 104\n",
      "Batch: 105\n",
      "Batch: 106\n",
      "Batch: 107\n",
      "Batch: 108\n",
      "Batch: 109\n",
      "Batch: 110\n",
      "Batch: 111\n",
      "Batch: 112\n",
      "Batch: 113\n",
      "Batch: 114\n",
      "Batch: 115\n",
      "Batch: 116\n",
      "Batch: 117\n",
      "Batch: 118\n",
      "Batch: 119\n",
      "Batch: 120\n",
      "Batch: 121\n",
      "Batch: 122\n",
      "Batch: 123\n",
      "Batch: 124\n",
      "Batch: 125\n",
      "Batch: 126\n",
      "Batch: 127\n",
      "Batch: 128\n",
      "Batch: 129\n",
      "Batch: 130\n",
      "Batch: 131\n",
      "Batch: 132\n",
      "Batch: 133\n",
      "Batch: 134\n",
      "Batch: 135\n",
      "Batch: 136\n",
      "Batch: 137\n",
      "Batch: 138\n",
      "Batch: 139\n",
      "Batch: 140\n",
      "Batch: 141\n",
      "Batch: 142\n",
      "Batch: 143\n",
      "Batch: 144\n",
      "Batch: 145\n",
      "Batch: 146\n",
      "Batch: 147\n",
      "Batch: 148\n",
      "Batch: 149\n",
      "Batch: 150\n",
      "Batch: 151\n",
      "Batch: 152\n",
      "Batch: 153\n",
      "Batch: 154\n",
      "Batch: 155\n",
      "Batch: 156\n",
      "Batch: 157\n",
      "Batch: 158\n",
      "Batch: 159\n",
      "Batch: 160\n",
      "Batch: 161\n",
      "Batch: 162\n",
      "Batch: 163\n",
      "Batch: 164\n",
      "Batch: 165\n",
      "Batch: 166\n",
      "Batch: 167\n",
      "Batch: 168\n",
      "Batch: 169\n",
      "Batch: 170\n",
      "Batch: 171\n",
      "Batch: 172\n",
      "Batch: 173\n",
      "Batch: 174\n",
      "Batch: 175\n",
      "Batch: 176\n",
      "Batch: 177\n",
      "Batch: 178\n",
      "Batch: 179\n",
      "Batch: 180\n",
      "Batch: 181\n",
      "Batch: 182\n",
      "Batch: 183\n",
      "Batch: 184\n",
      "Batch: 185\n",
      "Batch: 186\n",
      "Batch: 187\n",
      "Batch: 188\n",
      "Batch: 189\n",
      "Batch: 190\n",
      "Batch: 191\n",
      "Batch: 192\n",
      "Batch: 193\n",
      "Batch: 194\n",
      "Batch: 195\n",
      "Batch: 196\n",
      "Batch: 197\n",
      "Batch: 198\n",
      "Batch: 199\n",
      "Batch: 200\n",
      "textcat_loss: 10.572\t f1_score: 0.126\t accuracy_score: 0.285\n",
      "Elapsed time: 60.41 minutes\n",
      "Total time: 1.62 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy_transformers.language.TransformersLanguage at 0x7fec5b6139b0>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trial with train_data[:1000] on a transformer model\n",
    "trf_train_spacy(5, 0.2, 4e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try tuning hyperparameters to increase afficiency and accuracy\n",
    "- Implement this notebook with spacy 3.0\n",
    "- Need access to GPU for transformer models, training is way too slow on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
